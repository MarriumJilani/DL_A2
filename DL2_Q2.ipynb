{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc3ZsY8Ra4sd",
        "outputId": "e7a73925-b619-4885-fa1b-b54012a822ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (4.9.3)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas-datareader) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-datareader) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas-datareader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up Yahoo Finance API\n",
        "# Override the pandas datareader with Yahoo Finance\n",
        "# Define the stock symbol and date range\n",
        "# Fetch historical stock price data\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "\n",
        "import pandas as pd\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yf\n",
        "\n",
        "yf.pdr_override()\n",
        "\n",
        "stock_symbol = \"AAPL\"\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "\n",
        "stock_data = pdr.get_data_yahoo(stock_symbol, start=start_date, end=end_date)\n",
        "\n",
        "print(stock_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeZSw7nwfeoh",
        "outputId": "e2e6c747-7fa7-4103-e0c6-7bc59c40b436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "                  Open        High         Low       Close   Adj Close  \\\n",
            "Date                                                                     \n",
            "2022-01-03  177.830002  182.880005  177.710007  182.009995  180.190948   \n",
            "2022-01-04  182.630005  182.940002  179.119995  179.699997  177.904053   \n",
            "2022-01-05  179.610001  180.169998  174.639999  174.919998  173.171844   \n",
            "2022-01-06  172.699997  175.300003  171.639999  172.000000  170.281006   \n",
            "2022-01-07  172.889999  174.139999  171.029999  172.169998  170.449310   \n",
            "\n",
            "               Volume  \n",
            "Date                   \n",
            "2022-01-03  104487900  \n",
            "2022-01-04   99310400  \n",
            "2022-01-05   94537600  \n",
            "2022-01-06   96904000  \n",
            "2022-01-07   86709100  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data.fillna(stock_data.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "nKVmz_ALgEH_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max Scaling: This method scales the data to a specific range, often between 0 and 1. It's suitable for features with clear boundaries, like stock prices.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(stock_data)\n"
      ],
      "metadata": {
        "id": "GTZPCdRpgKH5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization (Z-Score Scaling): This method scales the data to have a mean of 0 and a standard deviation of 1. It's suitable for features that may not have clear boundaries.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "standardized_data = scaler.fit_transform(stock_data)\n"
      ],
      "metadata": {
        "id": "Rpes95tAgRjx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input sequence: OHLC prices and volumes for N days\n",
        " # Target sequence: Close price for the next day\n",
        "import numpy as np\n",
        "\n",
        "def create_sequences(data, input_seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - input_seq_length):\n",
        "        input_seq = data[i:i+input_seq_length, :]\n",
        "\n",
        "\n",
        "        target = data[i+input_seq_length, -1]  # Assuming the Close price is the last column\n",
        "\n",
        "        X.append(input_seq)\n",
        "        y.append(target)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "input_seq_length = 10\n",
        "X, y = create_sequences(scaled_data, input_seq_length)\n"
      ],
      "metadata": {
        "id": "A9OuE4Z3gred"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using LSTM with 64 units\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "def build_lstm_model(input_shape, lstm_units):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(lstm_units, input_shape=input_shape))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "lstm_model = build_lstm_model((input_seq_length, X.shape[2]), lstm_units=64)\n"
      ],
      "metadata": {
        "id": "oy0cwumXgx-x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 50\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(learning_rate=learning_rate))\n"
      ],
      "metadata": {
        "id": "_qawbg1QEGyy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "X-fIEq1nEK2I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTsFR_n8EhPC",
        "outputId": "e926b2f9-de7f-4513-eaec-875040a16936"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 - 2s - loss: 0.0685 - val_loss: 0.0456 - 2s/epoch - 794ms/step\n",
            "Epoch 2/50\n",
            "3/3 - 0s - loss: 0.0483 - val_loss: 0.0754 - 77ms/epoch - 26ms/step\n",
            "Epoch 3/50\n",
            "3/3 - 0s - loss: 0.0504 - val_loss: 0.0486 - 57ms/epoch - 19ms/step\n",
            "Epoch 4/50\n",
            "3/3 - 0s - loss: 0.0371 - val_loss: 0.0317 - 51ms/epoch - 17ms/step\n",
            "Epoch 5/50\n",
            "3/3 - 0s - loss: 0.0338 - val_loss: 0.0276 - 53ms/epoch - 18ms/step\n",
            "Epoch 6/50\n",
            "3/3 - 0s - loss: 0.0335 - val_loss: 0.0256 - 52ms/epoch - 17ms/step\n",
            "Epoch 7/50\n",
            "3/3 - 0s - loss: 0.0297 - val_loss: 0.0258 - 52ms/epoch - 17ms/step\n",
            "Epoch 8/50\n",
            "3/3 - 0s - loss: 0.0262 - val_loss: 0.0291 - 45ms/epoch - 15ms/step\n",
            "Epoch 9/50\n",
            "3/3 - 0s - loss: 0.0261 - val_loss: 0.0303 - 44ms/epoch - 15ms/step\n",
            "Epoch 10/50\n",
            "3/3 - 0s - loss: 0.0254 - val_loss: 0.0257 - 45ms/epoch - 15ms/step\n",
            "Epoch 11/50\n",
            "3/3 - 0s - loss: 0.0239 - val_loss: 0.0205 - 52ms/epoch - 17ms/step\n",
            "Epoch 12/50\n",
            "3/3 - 0s - loss: 0.0227 - val_loss: 0.0196 - 49ms/epoch - 16ms/step\n",
            "Epoch 13/50\n",
            "3/3 - 0s - loss: 0.0223 - val_loss: 0.0198 - 52ms/epoch - 17ms/step\n",
            "Epoch 14/50\n",
            "3/3 - 0s - loss: 0.0218 - val_loss: 0.0206 - 58ms/epoch - 19ms/step\n",
            "Epoch 15/50\n",
            "3/3 - 0s - loss: 0.0216 - val_loss: 0.0220 - 66ms/epoch - 22ms/step\n",
            "Epoch 16/50\n",
            "3/3 - 0s - loss: 0.0218 - val_loss: 0.0210 - 56ms/epoch - 19ms/step\n",
            "Epoch 17/50\n",
            "3/3 - 0s - loss: 0.0215 - val_loss: 0.0201 - 75ms/epoch - 25ms/step\n",
            "Epoch 18/50\n",
            "3/3 - 0s - loss: 0.0213 - val_loss: 0.0189 - 58ms/epoch - 19ms/step\n",
            "Epoch 19/50\n",
            "3/3 - 0s - loss: 0.0213 - val_loss: 0.0193 - 64ms/epoch - 21ms/step\n",
            "Epoch 20/50\n",
            "3/3 - 0s - loss: 0.0211 - val_loss: 0.0210 - 63ms/epoch - 21ms/step\n",
            "Epoch 21/50\n",
            "3/3 - 0s - loss: 0.0210 - val_loss: 0.0206 - 49ms/epoch - 16ms/step\n",
            "Epoch 22/50\n",
            "3/3 - 0s - loss: 0.0206 - val_loss: 0.0188 - 44ms/epoch - 15ms/step\n",
            "Epoch 23/50\n",
            "3/3 - 0s - loss: 0.0206 - val_loss: 0.0183 - 41ms/epoch - 14ms/step\n",
            "Epoch 24/50\n",
            "3/3 - 0s - loss: 0.0207 - val_loss: 0.0190 - 44ms/epoch - 15ms/step\n",
            "Epoch 25/50\n",
            "3/3 - 0s - loss: 0.0203 - val_loss: 0.0202 - 62ms/epoch - 21ms/step\n",
            "Epoch 26/50\n",
            "3/3 - 0s - loss: 0.0202 - val_loss: 0.0198 - 42ms/epoch - 14ms/step\n",
            "Epoch 27/50\n",
            "3/3 - 0s - loss: 0.0200 - val_loss: 0.0188 - 39ms/epoch - 13ms/step\n",
            "Epoch 28/50\n",
            "3/3 - 0s - loss: 0.0200 - val_loss: 0.0187 - 41ms/epoch - 14ms/step\n",
            "Epoch 29/50\n",
            "3/3 - 0s - loss: 0.0198 - val_loss: 0.0201 - 40ms/epoch - 13ms/step\n",
            "Epoch 30/50\n",
            "3/3 - 0s - loss: 0.0197 - val_loss: 0.0196 - 39ms/epoch - 13ms/step\n",
            "Epoch 31/50\n",
            "3/3 - 0s - loss: 0.0195 - val_loss: 0.0190 - 40ms/epoch - 13ms/step\n",
            "Epoch 32/50\n",
            "3/3 - 0s - loss: 0.0195 - val_loss: 0.0183 - 36ms/epoch - 12ms/step\n",
            "Epoch 33/50\n",
            "3/3 - 0s - loss: 0.0193 - val_loss: 0.0198 - 38ms/epoch - 13ms/step\n",
            "Epoch 34/50\n",
            "3/3 - 0s - loss: 0.0194 - val_loss: 0.0201 - 42ms/epoch - 14ms/step\n",
            "Epoch 35/50\n",
            "3/3 - 0s - loss: 0.0191 - val_loss: 0.0182 - 41ms/epoch - 14ms/step\n",
            "Epoch 36/50\n",
            "3/3 - 0s - loss: 0.0193 - val_loss: 0.0178 - 42ms/epoch - 14ms/step\n",
            "Epoch 37/50\n",
            "3/3 - 0s - loss: 0.0193 - val_loss: 0.0204 - 44ms/epoch - 15ms/step\n",
            "Epoch 38/50\n",
            "3/3 - 0s - loss: 0.0189 - val_loss: 0.0193 - 39ms/epoch - 13ms/step\n",
            "Epoch 39/50\n",
            "3/3 - 0s - loss: 0.0187 - val_loss: 0.0177 - 38ms/epoch - 13ms/step\n",
            "Epoch 40/50\n",
            "3/3 - 0s - loss: 0.0193 - val_loss: 0.0183 - 64ms/epoch - 21ms/step\n",
            "Epoch 41/50\n",
            "3/3 - 0s - loss: 0.0189 - val_loss: 0.0216 - 139ms/epoch - 46ms/step\n",
            "Epoch 42/50\n",
            "3/3 - 0s - loss: 0.0187 - val_loss: 0.0186 - 110ms/epoch - 37ms/step\n",
            "Epoch 43/50\n",
            "3/3 - 0s - loss: 0.0186 - val_loss: 0.0176 - 55ms/epoch - 18ms/step\n",
            "Epoch 44/50\n",
            "3/3 - 0s - loss: 0.0186 - val_loss: 0.0198 - 39ms/epoch - 13ms/step\n",
            "Epoch 45/50\n",
            "3/3 - 0s - loss: 0.0184 - val_loss: 0.0194 - 37ms/epoch - 12ms/step\n",
            "Epoch 46/50\n",
            "3/3 - 0s - loss: 0.0182 - val_loss: 0.0186 - 38ms/epoch - 13ms/step\n",
            "Epoch 47/50\n",
            "3/3 - 0s - loss: 0.0183 - val_loss: 0.0179 - 37ms/epoch - 12ms/step\n",
            "Epoch 48/50\n",
            "3/3 - 0s - loss: 0.0182 - val_loss: 0.0202 - 37ms/epoch - 12ms/step\n",
            "Epoch 49/50\n",
            "3/3 - 0s - loss: 0.0181 - val_loss: 0.0195 - 36ms/epoch - 12ms/step\n",
            "Epoch 50/50\n",
            "3/3 - 0s - loss: 0.0184 - val_loss: 0.0186 - 37ms/epoch - 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find accuracy on test data using MSE\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = lstm_model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Test MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsjCPfanEkgJ",
        "outputId": "594005a8-b9a8-4507-8cae-f9128c59bf64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "Test MSE: 0.011446811965379694\n"
          ]
        }
      ]
    }
  ]
}